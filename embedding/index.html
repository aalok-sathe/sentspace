<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>sentspace.embedding API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>sentspace.embedding</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
from collections import defaultdict
from pathlib import Path
from typing import List

import pandas as pd
import sentspace.lexical
import sentspace.utils
from pandas.core.frame import DataFrame
from sentspace.embedding import utils
from sentspace.utils import io, text
from sentspace.utils.caching import cache_to_disk, cache_to_mem
from tqdm import tqdm


def get_features(sentence: sentspace.Sentence.Sentence, vocab=None, data_dir=None):
    &#34;&#34;&#34;get embedding-based features (e.g. avg, min, max, etc.) for sentence.

    Args:
        sentence (str): sentence to get features for
        vocab ([set], optional): vocabulary of all sentences that will be processed in this session.
                                 it is recommended for a calling scope to make this available in order
                                 to save processing time of going through all of Glove each time.
                                 In the future, optimizations may be considered, such as, indexing the
                                 byte offset of a particular token in the Glove file for speedy reading.

    Returns:
        [type]: [description]
    &#34;&#34;&#34;

    # tokenized = text.tokenize(sentence)
    # tagged_sentence = text.get_pos_tags(tokenized)
    # is_content_word = sentspace.utils.text.get_is_content(tagged_sentence, content_pos=text.pos_for_content)
    # clean words: strip nonletters/punctuation and lowercase
    # nonletters = text.get_nonletters(tokenized, exceptions=[])  # find all non-letter characters in file
    # cleaned_sentence = text.strip_words(tokenized, method=&#39;nonletters&#39;,
    #                                     nonletters=text.get_nonletters(tokenized, exceptions=[]))
    # lowercased = [*map(lambda x: x.lower(), sentence.tokenized())]

    if vocab is None:
        io.log(f&#39;no vocabulary provided in advance. this may take a while. grab some popcorn ^.^&#39;, type=&#39;WARN&#39;)
    w2v = defaultdict(lambda: defaultdict(None))
    
    # if lock is not None:
    #     lock.acquire()
    w2v[&#39;glove&#39;] = utils.load_embeddings(emb_file=&#39;glove.840B.300d.txt&#39;,
                                         vocab=(*sorted(vocab or sentence.tokenized()),),
                                         data_dir=data_dir)
    # if lock is not None:
    #     lock.release()

    token_embeddings = {
        &#39;glove&#39;: utils.get_word_embeds(sentence, w2v=w2v,
                                       which=&#39;glove&#39;, dims=300),
    }

    content_word_filter = lambda i, token: sentence.content_words()[i]
    filters = {&#39;content_words&#39;: content_word_filter}
    pooled_embeddings = utils.pool_sentence_embeds(sentence, token_embeddings, filters=filters)

    lemmatized_sentence = text.get_lemmatized_tokens(sentence.tokenized(), sentence.pos_tagged())
    
    return {
        &#39;index&#39;: sentence.uid(),
        &#39;sentence&#39;: str(sentence),
        &#39;filters&#39;: &#39;,&#39;.join(filters.keys()),

        **pooled_embeddings,
    }


    # # Read in benchmark data
    # df_benchmark = pd.read_csv(benchmark_file)

    # # Return percentile per sentence for each
    # percentile_df = utils.return_percentile_df(df_benchmark, sent_embed)
    # print(&#39;Writing percentiles&#39;)
    # percentile_df.to_csv(bench_perc_out_path, index=False)</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="sentspace.embedding.utils" href="utils.html">sentspace.embedding.utils</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="sentspace.embedding.get_features"><code class="name flex">
<span>def <span class="ident">get_features</span></span>(<span>sentence:Â <a title="sentspace.Sentence.Sentence" href="../Sentence.html#sentspace.Sentence.Sentence">Sentence</a>, vocab=None, data_dir=None)</span>
</code></dt>
<dd>
<div class="desc"><p>get embedding-based features (e.g. avg, min, max, etc.) for sentence.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sentence</code></strong> :&ensp;<code>str</code></dt>
<dd>sentence to get features for</dd>
<dt><strong><code>vocab</code></strong> :&ensp;<code>[set]</code>, optional</dt>
<dd>vocabulary of all sentences that will be processed in this session.
it is recommended for a calling scope to make this available in order
to save processing time of going through all of Glove each time.
In the future, optimizations may be considered, such as, indexing the
byte offset of a particular token in the Glove file for speedy reading.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>[type]</code></dt>
<dd>[description]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_features(sentence: sentspace.Sentence.Sentence, vocab=None, data_dir=None):
    &#34;&#34;&#34;get embedding-based features (e.g. avg, min, max, etc.) for sentence.

    Args:
        sentence (str): sentence to get features for
        vocab ([set], optional): vocabulary of all sentences that will be processed in this session.
                                 it is recommended for a calling scope to make this available in order
                                 to save processing time of going through all of Glove each time.
                                 In the future, optimizations may be considered, such as, indexing the
                                 byte offset of a particular token in the Glove file for speedy reading.

    Returns:
        [type]: [description]
    &#34;&#34;&#34;

    # tokenized = text.tokenize(sentence)
    # tagged_sentence = text.get_pos_tags(tokenized)
    # is_content_word = sentspace.utils.text.get_is_content(tagged_sentence, content_pos=text.pos_for_content)
    # clean words: strip nonletters/punctuation and lowercase
    # nonletters = text.get_nonletters(tokenized, exceptions=[])  # find all non-letter characters in file
    # cleaned_sentence = text.strip_words(tokenized, method=&#39;nonletters&#39;,
    #                                     nonletters=text.get_nonletters(tokenized, exceptions=[]))
    # lowercased = [*map(lambda x: x.lower(), sentence.tokenized())]

    if vocab is None:
        io.log(f&#39;no vocabulary provided in advance. this may take a while. grab some popcorn ^.^&#39;, type=&#39;WARN&#39;)
    w2v = defaultdict(lambda: defaultdict(None))
    
    # if lock is not None:
    #     lock.acquire()
    w2v[&#39;glove&#39;] = utils.load_embeddings(emb_file=&#39;glove.840B.300d.txt&#39;,
                                         vocab=(*sorted(vocab or sentence.tokenized()),),
                                         data_dir=data_dir)
    # if lock is not None:
    #     lock.release()

    token_embeddings = {
        &#39;glove&#39;: utils.get_word_embeds(sentence, w2v=w2v,
                                       which=&#39;glove&#39;, dims=300),
    }

    content_word_filter = lambda i, token: sentence.content_words()[i]
    filters = {&#39;content_words&#39;: content_word_filter}
    pooled_embeddings = utils.pool_sentence_embeds(sentence, token_embeddings, filters=filters)

    lemmatized_sentence = text.get_lemmatized_tokens(sentence.tokenized(), sentence.pos_tagged())
    
    return {
        &#39;index&#39;: sentence.uid(),
        &#39;sentence&#39;: str(sentence),
        &#39;filters&#39;: &#39;,&#39;.join(filters.keys()),

        **pooled_embeddings,
    }


    # # Read in benchmark data
    # df_benchmark = pd.read_csv(benchmark_file)

    # # Return percentile per sentence for each
    # percentile_df = utils.return_percentile_df(df_benchmark, sent_embed)
    # print(&#39;Writing percentiles&#39;)
    # percentile_df.to_csv(bench_perc_out_path, index=False)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="sentspace" href="../index.html">sentspace</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="sentspace.embedding.utils" href="utils.html">sentspace.embedding.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="sentspace.embedding.get_features" href="#sentspace.embedding.get_features">get_features</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>